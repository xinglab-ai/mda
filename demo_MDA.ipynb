{"cells":[{"cell_type":"markdown","id":"204117e6","metadata":{},"source":"## The following code shows the MDA analyses of deep neural network (DNN) features at intermediate layers for five different tasks"},{"cell_type":"code","source":"# For the tasks below, five datasets analysed in the manuscript will be automatically loaded. \r\n# However, you can upload your own dataset, and analyze it using MDA\r\n# Our data were saved as .npy file to reduce the data size (normally .csv file needs more disk space). \r\n# However, .csv or other type of files can also be loaded and analyzed using MDA","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"d2a84f36","metadata":{},"outputs":[],"source":"# Load all necessary python packages needed for the reported analyses\n# in our manuscript\nimport warnings\n\n# Disable all warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\nimport matplotlib.pyplot as plt\nimport scipy\nimport scipy.io as sio\nimport sklearn\nimport umap\nimport pandas as pd\nfrom umap.parametric_umap import ParametricUMAP\nimport numpy as np\nfrom mda import *\n\n# Font size for all the MDA visualizations shown below   \nFS = 16"},{"cell_type":"markdown","id":"aa69c03c","metadata":{},"source":"## MDA analysis of the DNN features in superresolution task"},{"cell_type":"markdown","source":"### Superresolution Network\r\nIn the superresolution task, we employed the super resolution generative adversarial network (SRGAN) to enhance the resolution of dermoscopic images (ISIC-2019) from 32×32 to 64×64. The selected SRGAN is a well-established deep network for super resolution, which is composed of a generator and a discriminator. In our implementation, the generator contains 4 residual blocks with shortcut connection batch normalization and PReLU and 1 upsampling block; the discriminator contains 7 convolution layers with leaky RuLU.","metadata":{}},{"cell_type":"markdown","source":"### Dataset and feature selection\r\nWe adopted ISIC-2019 dataset, which consists of a total of 25,331 dermoscopic images, including 4522 melanoma, 12,875 melanocytic nevus, 3323 basal cell carcinoma, 867 actinic keratosis, 2624 benign keratosis, 239 dermatofibroma, 253 vascular lesion, and 628 squamous cell carcinoma cases.\r\n<br />To visualize the intermediate layers of the SRGAN, we selected features of (a) output of the first residual block, (b) output of the third residual block, (c) output of the fourth residual block, and (d) output of the upsampling block in the generator. In this demo, feature (d) is given as a example.\r\n","metadata":{}},{"cell_type":"code","source":"# Number of neighbors in MDA analyses\r\nneighborNum = 5\r\n\r\n# Load feature data extracted by the SRGAN at umsampling block from test images\r\ntestDataFeatures = np.load('../data/SR/feature4_test_pca.npy')\r\n# Load data labels (target high resolution images) corresponding to low resolution test images\r\nY = np.load('../data/SR/y_test.npy')\r\n# Reshape the target images into vectors so that they can be analyzed by MDA \r\nY = Y.reshape(Y.shape[0],-1)\r\n# Load output images prediced by the SRGAN\r\nY_pred = np.load('../data/SR/y_test_pred_trained.npy')\r\n# Reshape the predicted output images into vectors so that they can be analyzed by MDA \r\nY_pred = Y_pred.reshape(Y_pred.shape[0],-1)\r\n\r\n# Create color map for MDA visualization from the target manifold topology\r\nclusterIdx = discoverManifold(Y, neighborNum)\r\n# Compute the outline of the output manifold\r\nclusterIdx_pred = discoverManifold(Y_pred, neighborNum)\r\n# Use the outline of the output manifold to generate the MDA visualization of the SRGAN features\r\nYreg = mda(testDataFeatures,clusterIdx_pred)   \r\n\r\n# Plot the MDA results\r\nplt.figure(1)\r\nplt.scatter(Yreg[:,0],Yreg[:,1],c=clusterIdx.T, cmap='jet', s=5)\r\nplt.xlabel(\"MDA1\")\r\nplt.ylabel(\"MDA2\")\r\nplt.title('MDA visualization of the SRGAN features for superresolution task')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"d68dc5bd","metadata":{},"source":"## MDA analysis of the DNN features in segmentation task\r\n"},{"cell_type":"markdown","source":"### Segmentation Network\r\nIn the segmentation task, we employed Dense-UNet for automatic brain tumor segmentation from MR images. \r\nThe Dense-UNet combines the U-net with the dense concatenation to deepen the depth of the network architecture and achieve feature reuse. The network is formed from seven dense blocks (four in encoder and three in decoder), each of them stacks eight convolutional layers. Every two convolutional layers are linked together in a feed-forward mode to maximize feature reuse.\r\n","metadata":{}},{"cell_type":"markdown","source":"### Dataset and feature selection\r\nHere, we used BraTS 2018 dataset, which provides multimodality 3D MRI images with tumor segmentation labels annotated by physicians. \r\nThe dataset includes 484 cases in total, which can be divided into 210 high-grade gliomas (HGG) and 75 low-grade gliomas (LGG) cases. \r\n<br />To visualize the intermediate layers of the Dense-UNet, we selected features of (a) the second convolutional layer in the third dense block, \r\n(b) the 8th convolutional layer in the fourth dense block, (c) the second convolutional layer in the 6th dense block, \r\nand (d) the last convolutional layer before the final output. In this demo, feature (d) is given as a example.","metadata":{}},{"cell_type":"code","source":"# Load feature data extracted by the Dense-UNet from test images at the last layer before output \r\ntestDataFeatures = np.load('../data/Seg/feature4_test.npy')\r\n# Load data labels (segmented images) corresponding to input test images\r\nY = np.load('../data/Seg/y_test.npy')\r\n# Reshape the binary images into vectors\r\nY = Y.reshape(Y.shape[0],-1)\r\n# Load output segmentation prediced by the Dense-UNet\r\nY_pred = np.load('../data/Seg/y_test_pred_trained.npy')\r\n# Reshape the output binary images into vectors\r\nY_pred = Y_pred.reshape(Y_pred.shape[0],-1)\r\n\r\n# Create color map for MDA visualization from the topology of the target manifold   \r\nclusterIdx = discoverManifold(Y, neighborNum)\r\n# Compute the outline of the output manifold\r\nclusterIdx_pred = discoverManifold(Y_pred, neighborNum)\r\n# Use the outline of the output manifold to generate the MDA visualization of the Dense-UNet features\r\nYreg = mda(testDataFeatures,clusterIdx_pred)   \r\n\r\n# Plot the MDA results\r\nplt.figure(1)\r\nplt.scatter(Yreg[:,0],Yreg[:,1],c=clusterIdx.T, cmap='jet', s=5)\r\nplt.xlabel(\"MDA1\")\r\nplt.ylabel(\"MDA2\")\r\nplt.title('MDA visualization of the Dense-UNet features for segmentation task')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"e33601f5","metadata":{},"source":"## MDA analysis of the DNN features in survival prediction task"},{"cell_type":"markdown","source":"### Survival Prediction Network\r\nIn the survival prediction task, we established an MLP model to predict the survival days of cancer patients from genomics data. \r\nThe survival prediction network has six fully connected blocks in total, each containing two fully connected layers with the same dimension and one batch normalization layer. \r\nThe numbers of dimensions are reduced from 2048 to 1024, then 512, 256, 128 and 64. After that, a dropout layer with rate = 0.25 and a fully connected layer with channel = 4 are adopted. \r\nFinally, the 1-dimensional output gives the prediction of the patients’ survival days\r\n","metadata":{}},{"cell_type":"markdown","source":"### Dataset and feature selection\r\nA public dataset called Cancer Genome Atlas (TCGA) is employed, which provides gene expression (normalized RNA-seq) and patient survival data for 10,956 tumors from 33 cancer types.\r\nBefore training, data preprocessing was conducted. We first selected the cases where the information “days to death” is applicable, then standardize the survival days to 0-1 by dividing by the maximum value, \r\nfinally save the corresponding gene expression value of each case and process the data by z-score normalization. After preprocessing, the applicable data includes 2,892 cases, each containing the normalized expression value of 20,531 genes and standardized survival day.\r\n<br />To visualize the intermediate layers of the survival prediction network, we selected features of (a) the  second layers of the third fully connected blocks, (b) the  second layers of the fourth fully connected blocks, \r\n(c) the  second layers of the fifth fully connected blocks, and (d) the  second layers of the sixth fully connected blocks. In this demo, feature (d) is given as a example.","metadata":{}},{"cell_type":"code","source":"# Load feature data extracted by the MLP from test data at the 2nd layer of the 6th fully connected block\r\ntestDataFeatures = np.load('../data/SP/feature4_test.npy')\r\n# Load data labels (survival days) corresponding to input test genomics data\r\nY = np.load('../data/SP/y_test.npy')\r\nY = Y.reshape(Y.shape[0],-1)\r\n# Load output survival days prediced by the MLP\r\nY_pred = np.load('../data/SP/y_test_pred_trained.npy')\r\nY_pred = Y_pred.reshape(Y_pred.shape[0],-1)\r\n\r\n# Create color map for MDA visualization from the topology of the target manifold  \r\nclusterIdx = discoverManifold(Y, neighborNum)\r\n# Compute the outline of the output manifold\r\nclusterIdx_pred = discoverManifold(Y_pred, neighborNum)\r\n# Use the outline of the output manifold to generate the MDA visualization of the MLP features\r\nYreg = mda(testDataFeatures,clusterIdx_pred)   \r\n\r\n# Plot the MDA results\r\nplt.figure(1)\r\nplt.scatter(Yreg[:,0],Yreg[:,1],c=Y, cmap='jet', s=5)\r\nplt.xlabel(\"MDA1\")\r\nplt.ylabel(\"MDA2\")\r\nplt.title('MDA visualization of the MLP features for survival prediction task')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"6a97e22d","metadata":{},"source":"## MDA analysis of the DNN features in gene expression prediction task"},{"cell_type":"markdown","source":"### Gene Expression Network\r\nIn the gene expression task, we established a gene expression prediction network, which can effectively estimate the gene expression profiles for different chemical perturbations. \r\nThe gene expression prediction network first encode the textual string of molecule into one-hot vectors by using the SMILES grammar to parse this string into a parse tree, \r\nthen uses a grammar variational autoencoder (VAE) to embed the one-hot vectors to continuous latent representation, finally utilizes multilayer perceptron (MLP) to predict the expression profiles of 978 landmark genes.","metadata":{}},{"cell_type":"markdown","source":"### Dataset and feature selection\r\nThe LINCS L1000 project has collected gene expression profiles for thousands of perturbagens at a variety of time points, doses, and cell lines. \r\nHere, we selected Level 3 of the L1000 project, which includes quantile-normalized gene expression profiles of 978 landmark genes, to build up our training and testing set.\r\n<br />To visualize the intermediate layers of the gene expression prediction network, we selected features of (a) the first MLP layer, (b) the second MLP layer, (c) the third MLP layer, \r\nand (d) the fourth MLP layer. In this demo, feature (d) is given as a example.","metadata":{}},{"cell_type":"code","source":"# Load feature data extracted by the MLP from test data at the 4th layer\r\ntestDataFeatures = np.load('../data/GP/feature4_test.npy')\r\n# Load data labels (gene expressions) corresponding to input test gene expression data\r\nY = np.load('../data/GP/y_test.npy')\r\nY = Y.reshape(Y.shape[0],-1)\r\n# Load prediced gene expressions by the MLP\r\nY_pred = np.load('../data/GP/y_test_pred_trained.npy')\r\nY_pred = Y_pred.reshape(Y_pred.shape[0],-1)\r\n\r\n# Create color map for MDA visualization from the topology of the target manifold  \r\nclusterIdx = discoverManifold(Y, neighborNum)\r\n# Compute the outline of the output manifold\r\nclusterIdx_pred = discoverManifold(Y_pred, neighborNum)\r\n# Use the outline of the output manifold to generate the MDA visualization of the MLP features\r\nYreg = mda(testDataFeatures,clusterIdx_pred)   \r\n\r\n# Plot the MDA results\r\nplt.figure(1)\r\nplt.scatter(Yreg[:,0],Yreg[:,1],c=clusterIdx.T, cmap='jet', s=5)\r\nplt.xlabel(\"MDA1\")\r\nplt.ylabel(\"MDA2\")\r\nplt.title('MDA visualization of the MLP features for gene prediction task')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"a0672e72","metadata":{},"source":"## MDA analysis of the DNN features in classification task"},{"cell_type":"markdown","source":"### Classification Network\r\nIn the classification task, we utilized the ResNet50 model to classify the lung X-ray images.\r\nThe ResNet50 consists of 4 substructures, which respectively have 3, 4, 6, 3 residual blocks, containing 3 convolutional layers each. Shortcut connections are also equipped in all residual blocks to solve the degradation problem.  \r\n","metadata":{}},{"cell_type":"markdown","source":"### Dataset and feature selection\r\nThe COVID-19 radiography dataset contains 21,165 X-ray images in total, including 3616 COVID-19 positive cases along with 10,192 normal, 6012 lung opacity (non-COVID lung infection), and 1345 viral pneumonia cases.\r\n<br />To visualize the intermediate layers of the ResNet50, we selected features of (a) output of the 4th residual block’s last convolutional layer in substructure2, (b) output of the 2nd residual block’s last convolutional layer in substructure3, \r\n(c) output of the 6th residual block’s last convolutional layer in substructure3, and (d) output of the 3rd residual block’s last convolutional layer in substructure4.\r\nIn this demo, feature (d) is given as a example.\r\n","metadata":{}},{"cell_type":"code","source":"# Load feature data extracted by the ResNet50 from test x-ray images at the 3rd residual block's last convolutional\r\n# layer in substructure 4.\r\ntestDataFeatures = np.load('../data/CL/feature4_test.npy')\r\n# Load data labels (lung diseases including COVID) corresponding to input test lung x-ray images\r\nY = np.load('../data/CL/y_test.npy')\r\nY = Y.reshape(Y.shape[0],-1)\r\n# Load predicted labels by the ResNet50\r\nY_pred = np.load('../data/CL/y_test_pred_trained.npy')\r\nY_pred = Y_pred.reshape(Y_pred.shape[0],-1)\r\n\r\n# Compute the outline of the output manifold\r\nclusterIdx_pred = discoverManifold(Y_pred, neighborNum)\r\n# Use the outline of the output manifold to generate the MDA visualization of the ResNet50 features\r\nYreg = mda(testDataFeatures,clusterIdx_pred)   \r\n\r\n# Plot the MDA results\r\nplt.figure(1)\r\nplt.scatter(Yreg[:,0],Yreg[:,1],c=Y, cmap='jet', s=5)\r\nplt.xlabel(\"MDA1\")\r\nplt.ylabel(\"MDA2\")\r\nplt.title('MDA visualization of the ResNet50 features for classification task')","metadata":{},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}